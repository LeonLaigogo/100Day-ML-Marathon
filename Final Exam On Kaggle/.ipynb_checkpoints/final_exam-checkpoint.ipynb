{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare required image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2315 images belonging to 5 classes.\n",
      "Found 508 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './image_data_1/'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2315)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 508)\n",
    "# test_features, test_labels = extract_features(test_dir, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2315 images belonging to 5 classes.\n",
      "Found 508 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 8  \n",
    "epochs = 20\n",
    "data_augmentation = True\n",
    "image_size = (150, 150)\n",
    "num_classes = 5\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCheckpoint as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'vgg16_model.{epoch:03d}.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "289/289 [==============================] - 186s 642ms/step - loss: 1.0904 - acc: 0.5821 - val_loss: 1.5302 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72619, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.001.h5\n",
      "Epoch 2/80\n",
      "289/289 [==============================] - 201s 697ms/step - loss: 0.6524 - acc: 0.7711 - val_loss: 1.2070 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72619 to 0.77000, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.002.h5\n",
      "Epoch 3/80\n",
      "289/289 [==============================] - 201s 696ms/step - loss: 0.5533 - acc: 0.7980 - val_loss: 0.3647 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77000 to 0.78400, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.003.h5\n",
      "Epoch 4/80\n",
      "289/289 [==============================] - 184s 637ms/step - loss: 0.4919 - acc: 0.8231 - val_loss: 0.4852 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.78400 to 0.79800, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.004.h5\n",
      "Epoch 5/80\n",
      "289/289 [==============================] - 185s 642ms/step - loss: 0.4179 - acc: 0.8483 - val_loss: 0.1532 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.79800 to 0.80400, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.005.h5\n",
      "Epoch 6/80\n",
      "289/289 [==============================] - 184s 637ms/step - loss: 0.3731 - acc: 0.8604 - val_loss: 0.3511 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80400\n",
      "Epoch 7/80\n",
      "289/289 [==============================] - 185s 641ms/step - loss: 0.3608 - acc: 0.8661 - val_loss: 0.2104 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.80400 to 0.80600, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.007.h5\n",
      "Epoch 8/80\n",
      "289/289 [==============================] - 185s 641ms/step - loss: 0.3327 - acc: 0.8808 - val_loss: 0.1471 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.80600 to 0.82800, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.008.h5\n",
      "Epoch 9/80\n",
      "289/289 [==============================] - 184s 638ms/step - loss: 0.2933 - acc: 0.8958 - val_loss: 0.4772 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.82800 to 0.83400, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.009.h5\n",
      "Epoch 10/80\n",
      "289/289 [==============================] - 183s 634ms/step - loss: 0.2877 - acc: 0.8927 - val_loss: 0.6396 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.83400 to 0.84200, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.010.h5\n",
      "Epoch 11/80\n",
      "289/289 [==============================] - 185s 640ms/step - loss: 0.2557 - acc: 0.9046 - val_loss: 0.6772 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.84200\n",
      "Epoch 12/80\n",
      "289/289 [==============================] - 182s 630ms/step - loss: 0.2555 - acc: 0.9016 - val_loss: 0.1317 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.84200\n",
      "Epoch 13/80\n",
      "289/289 [==============================] - 180s 623ms/step - loss: 0.2321 - acc: 0.9198 - val_loss: 0.0724 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.84200\n",
      "Epoch 14/80\n",
      "289/289 [==============================] - 184s 638ms/step - loss: 0.2107 - acc: 0.9267 - val_loss: 0.0199 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.84200\n",
      "Epoch 15/80\n",
      "289/289 [==============================] - 189s 654ms/step - loss: 0.2154 - acc: 0.9181 - val_loss: 0.3923 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.84200\n",
      "Epoch 16/80\n",
      "289/289 [==============================] - 180s 623ms/step - loss: 0.1985 - acc: 0.9250 - val_loss: 0.1490 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.84200 to 0.84600, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.016.h5\n",
      "Epoch 17/80\n",
      "289/289 [==============================] - 182s 631ms/step - loss: 0.1770 - acc: 0.9337 - val_loss: 0.2975 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84600\n",
      "Epoch 18/80\n",
      "289/289 [==============================] - 184s 638ms/step - loss: 0.1693 - acc: 0.9376 - val_loss: 0.1012 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.84600 to 0.85600, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.018.h5\n",
      "Epoch 19/80\n",
      "289/289 [==============================] - 186s 643ms/step - loss: 0.1541 - acc: 0.9454 - val_loss: 0.0049 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.85600\n",
      "Epoch 20/80\n",
      "289/289 [==============================] - 189s 653ms/step - loss: 0.1537 - acc: 0.9497 - val_loss: 0.0684 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.85600 to 0.85800, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.020.h5\n",
      "Epoch 21/80\n",
      "289/289 [==============================] - 184s 637ms/step - loss: 0.1266 - acc: 0.9562 - val_loss: 0.0173 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.85800\n",
      "Epoch 22/80\n",
      "289/289 [==============================] - 182s 629ms/step - loss: 0.1287 - acc: 0.9593 - val_loss: 0.0022 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.85800\n",
      "Epoch 23/80\n",
      "289/289 [==============================] - 188s 652ms/step - loss: 0.1241 - acc: 0.9558 - val_loss: 1.0462 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.85800\n",
      "Epoch 24/80\n",
      "289/289 [==============================] - 188s 649ms/step - loss: 0.1135 - acc: 0.9593 - val_loss: 1.0029 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.85800\n",
      "Epoch 25/80\n",
      "289/289 [==============================] - 183s 632ms/step - loss: 0.1081 - acc: 0.9610 - val_loss: 0.4248 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.85800\n",
      "Epoch 26/80\n",
      "289/289 [==============================] - 184s 635ms/step - loss: 0.1006 - acc: 0.9627 - val_loss: 0.9811 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.85800\n",
      "Epoch 27/80\n",
      "289/289 [==============================] - 189s 653ms/step - loss: 0.0988 - acc: 0.9693 - val_loss: 0.6786 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.85800\n",
      "Epoch 28/80\n",
      "289/289 [==============================] - 188s 649ms/step - loss: 0.0928 - acc: 0.9696 - val_loss: 0.5456 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.85800 to 0.87000, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.028.h5\n",
      "Epoch 29/80\n",
      "289/289 [==============================] - 189s 654ms/step - loss: 0.0921 - acc: 0.9697 - val_loss: 0.2000 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.87000\n",
      "Epoch 30/80\n",
      "289/289 [==============================] - 184s 636ms/step - loss: 0.0852 - acc: 0.9697 - val_loss: 0.2341 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.87000\n",
      "Epoch 31/80\n",
      "289/289 [==============================] - 185s 640ms/step - loss: 0.0713 - acc: 0.9775 - val_loss: 0.0418 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.87000\n",
      "Epoch 32/80\n",
      "289/289 [==============================] - 182s 630ms/step - loss: 0.0813 - acc: 0.9744 - val_loss: 0.2280 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.87000\n",
      "Epoch 33/80\n",
      "289/289 [==============================] - 207s 716ms/step - loss: 0.0677 - acc: 0.9779 - val_loss: 0.1489 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.87000\n",
      "Epoch 34/80\n",
      "289/289 [==============================] - 193s 667ms/step - loss: 0.0665 - acc: 0.9757 - val_loss: 0.9692 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.87000\n",
      "Epoch 35/80\n",
      "289/289 [==============================] - 188s 650ms/step - loss: 0.0657 - acc: 0.9779 - val_loss: 0.5064 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.87000\n",
      "Epoch 36/80\n",
      "289/289 [==============================] - 187s 646ms/step - loss: 0.0572 - acc: 0.9801 - val_loss: 0.0953 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.87000\n",
      "Epoch 37/80\n",
      "289/289 [==============================] - 188s 649ms/step - loss: 0.0630 - acc: 0.9778 - val_loss: 0.0043 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.87000\n",
      "Epoch 38/80\n",
      "289/289 [==============================] - 188s 650ms/step - loss: 0.0727 - acc: 0.9762 - val_loss: 0.0016 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.87000\n",
      "Epoch 39/80\n",
      "289/289 [==============================] - 180s 624ms/step - loss: 0.0582 - acc: 0.9805 - val_loss: 0.5464 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.87000\n",
      "Epoch 40/80\n",
      "289/289 [==============================] - 181s 626ms/step - loss: 0.0566 - acc: 0.9822 - val_loss: 2.9258 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.87000\n",
      "Epoch 41/80\n",
      "289/289 [==============================] - 182s 630ms/step - loss: 0.0486 - acc: 0.9840 - val_loss: 1.1276 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.87000\n",
      "Epoch 42/80\n",
      "289/289 [==============================] - 182s 631ms/step - loss: 0.0528 - acc: 0.9840 - val_loss: 0.6789 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.87000\n",
      "Epoch 43/80\n",
      "289/289 [==============================] - 182s 628ms/step - loss: 0.0455 - acc: 0.9835 - val_loss: 0.0336 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.87000\n",
      "Epoch 44/80\n",
      "289/289 [==============================] - 188s 650ms/step - loss: 0.0529 - acc: 0.9818 - val_loss: 0.0036 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.87000\n",
      "Epoch 45/80\n",
      "289/289 [==============================] - 185s 639ms/step - loss: 0.0512 - acc: 0.9835 - val_loss: 0.0796 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.87000\n",
      "Epoch 46/80\n",
      "289/289 [==============================] - 185s 642ms/step - loss: 0.0574 - acc: 0.9792 - val_loss: 0.1792 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.87000\n",
      "Epoch 47/80\n",
      "289/289 [==============================] - 185s 641ms/step - loss: 0.0448 - acc: 0.9835 - val_loss: 4.6521e-05 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.87000\n",
      "Epoch 48/80\n",
      "289/289 [==============================] - 179s 620ms/step - loss: 0.0386 - acc: 0.9883 - val_loss: 0.2168 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.87000\n",
      "Epoch 49/80\n",
      "289/289 [==============================] - 181s 628ms/step - loss: 0.0424 - acc: 0.9848 - val_loss: 1.3830 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.87000\n",
      "Epoch 50/80\n",
      "289/289 [==============================] - 186s 644ms/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.7218 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.87000\n",
      "Epoch 51/80\n",
      "289/289 [==============================] - 181s 625ms/step - loss: 0.0262 - acc: 0.9939 - val_loss: 1.5496 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.87000\n",
      "Epoch 52/80\n",
      "289/289 [==============================] - 184s 637ms/step - loss: 0.0540 - acc: 0.9818 - val_loss: 0.5561 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.87000\n",
      "Epoch 53/80\n",
      "289/289 [==============================] - 185s 639ms/step - loss: 0.0396 - acc: 0.9861 - val_loss: 0.0197 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.87000\n",
      "Epoch 54/80\n",
      "289/289 [==============================] - 188s 650ms/step - loss: 0.0348 - acc: 0.9879 - val_loss: 0.0412 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.87000\n",
      "Epoch 55/80\n",
      "289/289 [==============================] - 188s 650ms/step - loss: 0.0449 - acc: 0.9866 - val_loss: 1.2405 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.87000\n",
      "Epoch 56/80\n",
      "289/289 [==============================] - 203s 701ms/step - loss: 0.0218 - acc: 0.9935 - val_loss: 1.2457 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.87000\n",
      "Epoch 57/80\n",
      "289/289 [==============================] - 186s 642ms/step - loss: 0.0426 - acc: 0.9848 - val_loss: 0.1991 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.87000\n",
      "Epoch 58/80\n",
      "289/289 [==============================] - 184s 638ms/step - loss: 0.0496 - acc: 0.9840 - val_loss: 2.1062 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.87000\n",
      "Epoch 59/80\n",
      "289/289 [==============================] - 182s 631ms/step - loss: 0.0280 - acc: 0.9918 - val_loss: 0.2980 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.87000\n",
      "Epoch 60/80\n",
      "289/289 [==============================] - 184s 636ms/step - loss: 0.0265 - acc: 0.9909 - val_loss: 0.4717 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.87000\n",
      "Epoch 61/80\n",
      "289/289 [==============================] - 183s 635ms/step - loss: 0.0277 - acc: 0.9922 - val_loss: 9.5220e-06 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.87000\n",
      "Epoch 62/80\n",
      "289/289 [==============================] - 184s 636ms/step - loss: 0.0333 - acc: 0.9861 - val_loss: 0.3320 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.87000\n",
      "Epoch 63/80\n",
      "289/289 [==============================] - 183s 633ms/step - loss: 0.0299 - acc: 0.9918 - val_loss: 0.0310 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87000 to 0.87800, saving model to D:\\數據分析\\3. Self\\100Day-ML-Marathon\\Final Exam On Kaggle\\saved_models\\vgg16_model.063.h5\n",
      "Epoch 64/80\n",
      "289/289 [==============================] - 186s 642ms/step - loss: 0.0245 - acc: 0.9926 - val_loss: 1.7289 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.87800\n",
      "Epoch 65/80\n",
      "289/289 [==============================] - 186s 643ms/step - loss: 0.0154 - acc: 0.9952 - val_loss: 0.0551 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.87800\n",
      "Epoch 66/80\n",
      "289/289 [==============================] - 182s 630ms/step - loss: 0.0217 - acc: 0.9931 - val_loss: 2.0156 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.87800\n",
      "Epoch 67/80\n",
      "289/289 [==============================] - 186s 644ms/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.0055 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.87800\n",
      "Epoch 68/80\n",
      "289/289 [==============================] - 188s 652ms/step - loss: 0.0296 - acc: 0.9905 - val_loss: 0.9877 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.87800\n",
      "Epoch 69/80\n",
      "289/289 [==============================] - 185s 641ms/step - loss: 0.0189 - acc: 0.9948 - val_loss: 2.5565e-04 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.87800\n",
      "Epoch 70/80\n",
      "289/289 [==============================] - 183s 634ms/step - loss: 0.0210 - acc: 0.9931 - val_loss: 1.5031 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.87800\n",
      "Epoch 71/80\n",
      "289/289 [==============================] - 181s 626ms/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.0522 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.87800\n",
      "Epoch 72/80\n",
      "289/289 [==============================] - 187s 646ms/step - loss: 0.0202 - acc: 0.9948 - val_loss: 8.6504e-06 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.87800\n",
      "Epoch 73/80\n",
      "289/289 [==============================] - 181s 626ms/step - loss: 0.0199 - acc: 0.9939 - val_loss: 0.1810 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.87800\n",
      "Epoch 74/80\n",
      "289/289 [==============================] - 184s 638ms/step - loss: 0.0259 - acc: 0.9917 - val_loss: 1.6944 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.87800\n",
      "Epoch 75/80\n",
      "289/289 [==============================] - 186s 642ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 1.0306 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.87800\n",
      "Epoch 76/80\n",
      "289/289 [==============================] - 183s 633ms/step - loss: 0.0155 - acc: 0.9961 - val_loss: 0.6901 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.87800\n",
      "Epoch 77/80\n",
      "289/289 [==============================] - 183s 634ms/step - loss: 0.0181 - acc: 0.9948 - val_loss: 0.9803 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.87800\n",
      "Epoch 78/80\n",
      "289/289 [==============================] - 189s 654ms/step - loss: 0.0272 - acc: 0.9926 - val_loss: 3.6378e-05 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.87800\n",
      "Epoch 79/80\n",
      "289/289 [==============================] - 189s 653ms/step - loss: 0.0356 - acc: 0.9896 - val_loss: 0.1106 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.87800\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 185s 641ms/step - loss: 0.0250 - acc: 0.9926 - val_loss: 2.4679 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.87800\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.adam(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "steps_per_epoch = 2315 // batch_size\n",
    "validation_steps = 508 // batch_size\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      epochs=80,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_steps,\n",
    "      verbose=1,\n",
    "      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and generate submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_filenames = os.listdir(test_dir)\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    test_dir, \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5)\n"
     ]
    }
   ],
   "source": [
    "steps = np.ceil(test_generator.samples / batch_size)\n",
    "predict = model.predict_generator(test_generator, steps=steps)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flower_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0028624c49b3e0610ff9f1d111f5d532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002c30700185b7971369258b438070d5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00852f4f666acecd0c0d140365b42efd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c08828fce04e360c732cac01edad9e</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d366e7877b6a78b104b57d67b60e6b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  flower_class\n",
       "0  0028624c49b3e0610ff9f1d111f5d532             2\n",
       "1  002c30700185b7971369258b438070d5             4\n",
       "2  00852f4f666acecd0c0d140365b42efd             4\n",
       "3  00c08828fce04e360c732cac01edad9e             4\n",
       "4  00d366e7877b6a78b104b57d67b60e6b             2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df[\"id\"] = [name.split('.')[0] for name in test_generator.filenames]\n",
    "submission_df['flower_class'] = np.argmax(predict, axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'vgg_16_pix150_epoch_80_call_back_val_acc_0.878.csv'\n",
    "submission_df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
